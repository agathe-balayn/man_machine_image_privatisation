{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from shapely.geometry import Polygon\n",
    "import image_slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLab code:\n",
    "# taken from https://gluon-cv.mxnet.io/build/examples_segmentation/demo_deeplab.html\n",
    "# dataset description https://groups.csail.mit.edu/vision/datasets/ADE20K/, https://github.com/dmlc/gluon-cv/blob/master/gluoncv/data/ade20k/segmentation.py\n",
    "# deeplab code https://github.com/dmlc/gluon-cv/blob/master/gluoncv/model_zoo/deeplabv3.py\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import image\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "import gluoncv\n",
    "from gluoncv.data.transforms.presets.segmentation import test_transform\n",
    "\n",
    "# using cpu\n",
    "ctx = mx.cpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR code\n",
    "#import pytesseract\n",
    "#from pytesseract import Output\n",
    "\n",
    "\n",
    "# If you don't have tesseract executable in your PATH, include the following:\n",
    "#pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' # Path('C:/Program Files\\ Tesseract-OCR\\ tesseract').as_posix()\n",
    "import OCR_utils as OCR_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Scene recognition imports\n",
    "from Keras_VGG16_places365.vgg16_places_365 import VGG16_Places365\n",
    "from cv2 import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing functions for tesseract (OCR)\n",
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\n",
    "def prepare_dataset(path_image_folder, model_type):\n",
    "    list_image = []\n",
    "    # Go through the directory\n",
    "    list_image_names = []\n",
    "    pathlist = Path(path_image_folder).glob('**/*.*')\n",
    "    for path in pathlist:\n",
    "        # because path is object not string\n",
    "        path_in_str = str(path)\n",
    "        list_image_names.append(path.stem)\n",
    "        # print(path_in_str)\n",
    "        \n",
    "        # check for which model the data will be used and pre-process accordingly.\n",
    "        if model_type == 'deeplab':\n",
    "            img = image.imread(path_in_str)\n",
    "            img = test_transform(img, ctx)\n",
    "        \n",
    "        elif model_type == 'OCR':\n",
    "            img = cv2.imread(path_in_str)\n",
    "            img = get_grayscale(img)\n",
    "            img = thresholding(img)\n",
    "        \n",
    "        elif model_type == 'vgg_places365':\n",
    "            img = Image.open(path_in_str)\n",
    "            img = np.array(img, dtype=np.uint8)\n",
    "            img = resize(img, (224, 224))\n",
    "            img = np.expand_dims(img, 0)\n",
    "\n",
    "        list_image.append(img)\n",
    "\n",
    "    return list_image, list_image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_deeplab, list_image_names_deeplab = prepare_dataset('../small_test2017/', 'deeplab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_OCR, list_image_names_OCR = prepare_dataset('../small_test2017/', 'OCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_scene, list_image_names_scene = prepare_dataset('../small_test2017/', 'vgg_places365')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check that the images are ordred similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_type):\n",
    "    if model_type == 'deeplab':\n",
    "        model = gluoncv.model_zoo.get_model('deeplab_resnet101_ade', pretrained=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADE dataset classes # numbered from 0!\n",
    "CLASSES = (\"wall\", \"building, edifice\", \"sky\", \"floor, flooring\", \"tree\",\n",
    "               \"ceiling\", \"road, route\", \"bed\", \"windowpane, window\", \"grass\",\n",
    "               \"cabinet\", \"sidewalk, pavement\",\n",
    "               \"person, individual, someone, somebody, mortal, soul\",\n",
    "               \"earth, ground\", \"door, double door\", \"table\", \"mountain, mount\",\n",
    "               \"plant, flora, plant life\", \"curtain, drape, drapery, mantle, pall\",\n",
    "               \"chair\", \"car, auto, automobile, machine, motorcar\",\n",
    "               \"water\", \"painting, picture\", \"sofa, couch, lounge\", \"shelf\",\n",
    "               \"house\", \"sea\", \"mirror\", \"rug, carpet, carpeting\", \"field\", \"armchair\",\n",
    "               \"seat\", \"fence, fencing\", \"desk\", \"rock, stone\", \"wardrobe, closet, press\",\n",
    "               \"lamp\", \"bathtub, bathing tub, bath, tub\", \"railing, rail\", \"cushion\",\n",
    "               \"base, pedestal, stand\", \"box\", \"column, pillar\", \"signboard, sign\",\n",
    "               \"chest of drawers, chest, bureau, dresser\", \"counter\", \"sand\", \"sink\",\n",
    "               \"skyscraper\", \"fireplace, hearth, open fireplace\", \"refrigerator, icebox\",\n",
    "               \"grandstand, covered stand\", \"path\", \"stairs, steps\", \"runway\",\n",
    "               \"case, display case, showcase, vitrine\",\n",
    "               \"pool table, billiard table, snooker table\", \"pillow\",\n",
    "               \"screen door, screen\", \"stairway, staircase\", \"river\", \"bridge, span\",\n",
    "               \"bookcase\", \"blind, screen\", \"coffee table, cocktail table\",\n",
    "               \"toilet, can, commode, crapper, pot, potty, stool, throne\",\n",
    "               \"flower\", \"book\", \"hill\", \"bench\", \"countertop\",\n",
    "               \"stove, kitchen stove, range, kitchen range, cooking stove\",\n",
    "               \"palm, palm tree\", \"kitchen island\",\n",
    "               \"computer, computing machine, computing device, data processor, \"\n",
    "               \"electronic computer, information processing system\",\n",
    "               \"swivel chair\", \"boat\", \"bar\", \"arcade machine\",\n",
    "               \"hovel, hut, hutch, shack, shanty\",\n",
    "               \"bus, autobus, coach, charabanc, double-decker, jitney, motorbus, \"\n",
    "               \"motorcoach, omnibus, passenger vehicle\",\n",
    "               \"towel\", \"light, light source\", \"truck, motortruck\", \"tower\",\n",
    "               \"chandelier, pendant, pendent\", \"awning, sunshade, sunblind\",\n",
    "               \"streetlight, street lamp\", \"booth, cubicle, stall, kiosk\",\n",
    "               \"television receiver, television, television set, tv, tv set, idiot \"\n",
    "               \"box, boob tube, telly, goggle box\",\n",
    "               \"airplane, aeroplane, plane\", \"dirt track\",\n",
    "               \"apparel, wearing apparel, dress, clothes\",\n",
    "               \"pole\", \"land, ground, soil\",\n",
    "               \"bannister, banister, balustrade, balusters, handrail\",\n",
    "               \"escalator, moving staircase, moving stairway\",\n",
    "               \"ottoman, pouf, pouffe, puff, hassock\",\n",
    "               \"bottle\", \"buffet, counter, sideboard\",\n",
    "               \"poster, posting, placard, notice, bill, card\",\n",
    "               \"stage\", \"van\", \"ship\", \"fountain\",\n",
    "               \"conveyer belt, conveyor belt, conveyer, conveyor, transporter\",\n",
    "               \"canopy\", \"washer, automatic washer, washing machine\",\n",
    "               \"plaything, toy\", \"swimming pool, swimming bath, natatorium\",\n",
    "               \"stool\", \"barrel, cask\", \"basket, handbasket\", \"waterfall, falls\",\n",
    "               \"tent, collapsible shelter\", \"bag\", \"minibike, motorbike\", \"cradle\",\n",
    "               \"oven\", \"ball\", \"food, solid food\", \"step, stair\", \"tank, storage tank\",\n",
    "               \"trade name, brand name, brand, marque\", \"microwave, microwave oven\",\n",
    "               \"pot, flowerpot\", \"animal, animate being, beast, brute, creature, fauna\",\n",
    "               \"bicycle, bike, wheel, cycle\", \"lake\",\n",
    "               \"dishwasher, dish washer, dishwashing machine\",\n",
    "               \"screen, silver screen, projection screen\",\n",
    "               \"blanket, cover\", \"sculpture\", \"hood, exhaust hood\", \"sconce\", \"vase\",\n",
    "               \"traffic light, traffic signal, stoplight\", \"tray\",\n",
    "               \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, \"\n",
    "               \"dustbin, trash barrel, trash bin\",\n",
    "               \"fan\", \"pier, wharf, wharfage, dock\", \"crt screen\",\n",
    "               \"plate\", \"monitor, monitoring device\", \"bulletin board, notice board\",\n",
    "               \"shower\", \"radiator\", \"glass, drinking glass\", \"clock\", \"flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(input_data, model_type, loaded_model=''):\n",
    "    \n",
    "    if model_type == 'vgg_places365':\n",
    "        file_name = Path('Keras_VGG16_places365/categories_places365.txt')\n",
    "        if not os.access(file_name, os.W_OK):\n",
    "            synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "            os.system('wget ' + synset_url)\n",
    "        classes = list()\n",
    "        with open(file_name) as class_file:\n",
    "            for line in class_file:\n",
    "                classes.append(line.strip().split(' ')[0][3:])\n",
    "        classes = tuple(classes)\n",
    "    \n",
    "    output = []\n",
    "    for img in input_data:\n",
    "        if model_type == 'deeplab':\n",
    "            pred = loaded_model.predict(img)\n",
    "            # Check what the outputs of predict are: is it probability? does it depend on the class or is it class-agnostic?\n",
    "            idx_labels = mx.nd.squeeze(mx.nd.argmax(pred, 1)).asnumpy()\n",
    "            # Decide later whether we make it into actual labels.\n",
    "            output.append((pred, idx_labels)) # this gives both the prediction \"confidence\" and the final label (in idx).\n",
    "        elif model_type == 'OCR': \n",
    "            pred = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "            prediction_list = []\n",
    "            # Get the boundix boxes around the words\n",
    "            n_boxes = len(pred['text'])\n",
    "            for i in range(n_boxes):\n",
    "                # if int(pred['conf'][i]) > 60: to filter per confidence ! see later!\n",
    "                (x, y, w, h) = (pred['left'][i], pred['top'][i], pred['width'][i], pred['height'][i])\n",
    "                prediction_list.append((pred['text'][i], (x, y, w, h)))\n",
    "            output.append(prediction_list)\n",
    "        elif model_type == 'vgg_places365':\n",
    "            model = VGG16_Places365(weights='places')\n",
    "            #predictions_to_return = 5\n",
    "            preds = model.predict(img)[0]\n",
    "            top_preds = np.argsort(preds)[::-1]#[0:predictions_to_return]\n",
    "            top_preds_score = [preds[i] for i in top_preds]\n",
    "            prediction_list = []\n",
    "            for i in range(0, len(top_preds)):\n",
    "                prediction_list.append((classes[top_preds[i]], top_preds_score[i]))\n",
    "            output.append(prediction_list)\n",
    "\n",
    "    return output\n",
    "        \n",
    "    # Add post processing to reshape the image / bounding boxes /  to original size\n",
    "    # It seems there's no need for that becaause only the scene recognition model needs resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_list_deeplab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-216779b8819b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_deeplab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'deeplab'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moutput_pred_deeplab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_list_deeplab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deeplab'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_deeplab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'image_list_deeplab' is not defined"
     ]
    }
   ],
   "source": [
    "model_deeplab = load_model('deeplab')\n",
    "output_pred_deeplab = get_predictions(image_list_deeplab, 'deeplab', model_deeplab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_ocr = get_predictions(image_list_OCR, 'OCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_scene = get_predictions(image_list_scene, 'vgg_places365')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_pred_scene)\n",
    "print(output_pred_ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-c517b6bacef6>, line 187)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-36-c517b6bacef6>\"\u001b[1;36m, line \u001b[1;32m187\u001b[0m\n\u001b[1;33m    dict_iou[param_eval] = # FOr each privacy element, go through its list and compute number of well predicted and total number\u001b[0m\n\u001b[1;37m                                                                                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0, s1), (s2, s3), (s4, s5), ...\"\n",
    "    a = iter(iterable)\n",
    "    return zip(a, a)\n",
    "\n",
    "def create_image_mask(image, polygon):\n",
    "    # From an image and the coordinates of a polygon, create a binary matrix (1 when in the polygon, 0 otherwise).\n",
    "    nx, ny = im.size\n",
    "    img = Image.new(\"L\", [nx, ny], 0)\n",
    "    ImageDraw.Draw(img).polygon(poly, outline=1, fill=1)\n",
    "    mask = np.array(img)\n",
    "    return mask\n",
    "\n",
    "def combine_image_masks(list_masks):\n",
    "    new_mask = list_masks[0]\n",
    "    if len(list_masks) > 1:\n",
    "        for m in range(1, len(list_masks)):\n",
    "            new_mask = np.add(new_mask, list_masks[m])\n",
    "    # Convert back to binary matrix\n",
    "    new_mask = np.where(new_mask > 0, 1, 0)\n",
    "    return new_mask\n",
    "\n",
    "def compute_mask_accuracy(GT_mask, pred_mask):\n",
    "    # Get total number of pixels for the GT mask\n",
    "    n_pixel_total = (GT_mask == 1).sum()\n",
    "    # Get number of overlapping pixels with the GT mask\n",
    "    mask_diff = np.subtract(GT_mask, pred_mask)\n",
    "    n_incorrect_pixel = (mask_diff == 1).sum()\n",
    "    acc = (n_pixel_total - n_incorrect_pixel) / n_pixel_total\n",
    "    return acc\n",
    "    \n",
    "def evaluate_privacy(priv_elem_GT, predictions, image):\n",
    "        \n",
    "    # Go through each private element in predictions\n",
    "    print(\"TODO: read predictions.\")\n",
    "    list_poly_pred = []\n",
    "\n",
    "    \n",
    "    dict_iou = {}\n",
    "    \n",
    "    ### Compute overlap\n",
    "    for instance_priv in priv_elem_GT:\n",
    "            \n",
    "        for instance_priv_poly in priv_elem_GT[instance_priv]:\n",
    "            # Compute IoU for each prediction\n",
    "            a = Polygon(instance_priv_poly)\n",
    "            \n",
    "            iou_preds = []\n",
    "            # Get the max IoU with all the predicted things.\n",
    "            for poly in list_poly_pred:\n",
    "                b = Polygon(poly)\n",
    "                iou_preds.append(a.intersection(b).area / a.union(b).area)\n",
    "            \n",
    "            if instance_priv in dict_iou:\n",
    "                dict_iou[instance_priv].append(max(iou_preds))\n",
    "            else:\n",
    "                dict_iou[instance_priv] = max(iou_preds)\n",
    "                \n",
    "    \n",
    "    ### Compute pixel-wise privacy-element -wise accuracy  \n",
    "    dict_pixel_perf = {}\n",
    "    # Get the mask for the predictions\n",
    "    list_mask_pred = []\n",
    "    for poly in list_poly_pred:\n",
    "        list_mask_pred.append(create_image_mask(image, poly))\n",
    "    pred_mask = combine_image_masks(list_mask_pred)\n",
    "                         \n",
    "    # Go through each private element of each category\n",
    "    for instance_priv in priv_elem_GT:\n",
    "        # Create the binary mask for the private element:\n",
    "        list_masks_GT = []\n",
    "        for instance_priv_poly in priv_elem_GT[instance_priv]:\n",
    "            # Compare each pixel of the private element\n",
    "            list_masks_GT.append(create_image_mask(image, instance_priv_poly))\n",
    "        GT_mask = combine_image_masks(list_masks_GT)\n",
    "    \n",
    "        # Check 1 if obfuscated, 0 otherwise. \n",
    "        # Get accuracy. (number 1 / total number pixels)\n",
    "        acc = compute_mask_accuracy(GT_mask, pred_mask)\n",
    "        dict_pixel_perf[instance_priv] = acc\n",
    "    return dict_iou, dict_pixel_perf\n",
    "\n",
    "                         \n",
    "def GT_annotation_to_polygon_dict(ground_truth):\n",
    "    priv_elem_GT = {}\n",
    "    for private_elem in ground_truth['attributes']:\n",
    "        name = private_elem['attr_id']\n",
    "        list_polygons = private_elem['polygons']\n",
    "        # Reshape the polygons into a readable format.\n",
    "        readable_poly = []\n",
    "        for poly in list_polygons:\n",
    "            p = []\n",
    "            for x, y in pairwise(poly):\n",
    "                p.append((x, y))\n",
    "            readable_poly.append(p)  \n",
    "        if name in priv_elem_GT:\n",
    "            priv_elem_GT[name].append(readable_poly)\n",
    "        else:\n",
    "            priv_elem_GT[name] = readable_poly\n",
    "    return priv_elem_GT\n",
    "                         \n",
    "def segment_array(array, segmentation_size):\n",
    "    im_w = array.shape[1] \n",
    "    im_h = array.shape[0]\n",
    "    print(\"TODO: check the validity / col/row\")\n",
    "    columns, rows = image_slicer.calc_columns_rows(segmentation_size)\n",
    "    tile_w, tile_h = int(floor(im_w / columns)), int(floor(im_h / rows))\n",
    "    segments = []\n",
    "    for pos_y in range(0, im_h - rows, tile_h): # -rows for rounding error.\n",
    "        for pos_x in range(0, im_w - columns, tile_w): # as above.\n",
    "            #area = (pos_x, pos_y, pos_x + tile_w, pos_y + tile_h)\n",
    "            segments.append[array[pos_x:(pos_x + tile_w)][pos_y:(pos_y + tile_h)]] \n",
    "            print(\"TODO: check the sizes\")\n",
    "    return segments\n",
    "                         \n",
    "def evaluate_instance(ground_truth, predictions, segmentation_size):\n",
    "    ### Compute the image masks\n",
    "    # For the GT\n",
    "    list_masks_GT = []\n",
    "    for instance_priv in priv_elem_GT:\n",
    "        # Create the binary mask for the private element:\n",
    "        for instance_priv_poly in priv_elem_GT[instance_priv]:\n",
    "            # Compare each pixel of the private element\n",
    "            list_masks_GT.append(create_image_mask(image, instance_priv_poly))\n",
    "    GT_mask = combine_image_masks(list_masks_GT)\n",
    "    # For the predictions\n",
    "    list_mask_pred = []\n",
    "    for poly in list_poly_pred:\n",
    "        list_mask_pred.append(create_image_mask(image, poly))\n",
    "    pred_mask = combine_image_masks(list_mask_pred)                     \n",
    "                         \n",
    "    ### Segment the masks\n",
    "    segments_GT = segment_array(GT_mask, segmentation_size)\n",
    "    segments_pred = segment_array(pred_mask, segmentation_size)\n",
    "    segment_size = segments_GT[0].shape[0] * segments_GT[0].shape[1]    \n",
    "    threshold_pixels = segment_size / 2\n",
    "    ### Compute numbers TP, TN, FP, FN\n",
    "    dict_counts = {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0}\n",
    "    for segment_GT, segment_pred in zip(segments_GT, segments_pred):\n",
    "        print(\"Check whether these rules are making sense.\")\n",
    "        print(\"For now, for each segment, we say that if more than half of the pixels are set to 1, then the segment is set at 1.\")\n",
    "        # Get the number of 1s in each segment and compare with the size of the segment.\n",
    "        nb_1_GT = (segment_GT == 1).sum()\n",
    "        nb_1_pred = (segment_pred == 1).sum()\n",
    "        if nb_1_GT > threshold_pixels: # It means the segment is positive.\n",
    "            if nb_1_pred > threshold_pixels: # It means the segment is predicted as positive.\n",
    "                dict_counts['TP'] += 1\n",
    "            else: \n",
    "                dict_counts['FN'] += 1\n",
    "        else:\n",
    "            if nb_1_pred > threshold_pixels:\n",
    "                dict_counts['FP'] += 1\n",
    "            else:\n",
    "                dict_counts['TN'] += 1\n",
    "            \n",
    "    precision = dict_counts['TP'] / (dict_counts['TP'] + dict_counts['FP'])\n",
    "    recall = dict_counts['TP'] / (dict_counts['TP'] + dict_counts['FN'])\n",
    "                         \n",
    "    ### Compute precision, recall\n",
    "    return {'precision': precision, 'recall': recall}\n",
    "\n",
    "def evaluate(ground_truth, predictions, evaluation_type, parameter_interval, list_image_names):\n",
    "    # ground_truth should be a list of dictionary of the private elements with their list of polygons\n",
    "    # priv_elem_GT = GT_annotation_to_polygon_dict(ground_truth)\n",
    "\n",
    "    if evaluation_type == 'privacy_type':\n",
    "        dict_iou = {}\n",
    "        dict_pixel = {}\n",
    "        for idx_im in range(len(predictions)):\n",
    "            # Get the ground truth \n",
    "            # Name of the image\n",
    "            im_name = list_image_names[idx_im]\n",
    "            result_per_iou, result_per_pixel = evaluate_privacy(ground_truth[im_name], predictions[idx_im])\n",
    "            for priv_elem in result_per_iou:\n",
    "                if priv_elem not in dict_iou:\n",
    "                    nb_pos = {'total_count': len(result_per_iou[priv_elem])}\n",
    "                    for param_eval in parameter_interval:\n",
    "                        if param_eval not in nb_pos:\n",
    "                                nb_pos[param_eval] = 0\n",
    "                        for result in result_per_iou[priv_elem]:\n",
    "                            if result > param_eval:\n",
    "                                nb_pos[param_eval] += 1 \n",
    "                    \n",
    "                    dict_iou[priv_elem] = nb_pos\n",
    "                else:\n",
    "                    dict_iou[priv_elem]['total_count'] += len(result_per_iou[priv_elem])\n",
    "                    for param_eval in parameter_interval:\n",
    "                        for result in result_per_iou[priv_elem]:\n",
    "                            if result > param_eval:\n",
    "                                dict_iou[priv_elem][param_eval] += 1 \n",
    "                    \n",
    "            for priv_elem in result_per_pixel:\n",
    "                if priv_elem not in dict_pixel:\n",
    "                    dict_pixel[priv_elem] = [result_per_pixel[priv_elem]]\n",
    "                else:\n",
    "                    dict_pixel[priv_elem].append(result_per_pixel[priv_elem])\n",
    "\n",
    "                \n",
    "        # And aggreagte for all the instances into a final score\n",
    "        score_iou_list = {}\n",
    "        for priv_elem in dict_iou:\n",
    "            dict_per_threshold = {}\n",
    "            for param_eval in dict_iou[priv_elem]:\n",
    "                if param_eval != 'total_count':\n",
    "                    dict_per_threshold[param_eval] = dict_iou[priv_elem][param_eval] / dict_iou[priv_elem][total_count]\n",
    "            score_iou_list[priv_elem] = dict_per_threshold\n",
    "        score_pixel_list = {}\n",
    "        for priv_elem in dict_pixel:\n",
    "            score_pixel_list[priv_elem] = np.mean(dict_pixel[priv_elem])\n",
    "            \n",
    "        return score_iou_list, score_pixel_list \n",
    "            \n",
    "    elif evaluation_type == 'instance_type':\n",
    "        dict_segment_result = {}\n",
    "        for param_eval in parameter_interval:\n",
    "            dict_segment_result[param_eval] = {'precision': [], 'recall': []}\n",
    "            for idx_im in range(len(predictions)):\n",
    "                im_name = list_image_names[idx_im]\n",
    "                result = evaluate_instance(ground_truth[im_name], predictions[idx_im], param_eval)\n",
    "                dict_segment_result[param_eval]['precision'].append(result['precision'])\n",
    "                dict_segment_result[param_eval]['recall'].append(result['recall'])\n",
    "            dict_segment_result[param_eval]['precision'] = np.mean(dict_segment_result[param_eval]['precision'])\n",
    "            dict_segment_result[param_eval]['recall'] = np.mean(dict_segment_result[param_eval]['recall'])\n",
    "        return dict_segment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read ground truth file and get the actual annotations\n",
    "with open(Path('../test2017.json'), 'r') as f:\n",
    "    ground_truth = json.load(f)\n",
    "ground_truth = ground_truth['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy_image_3_7",
   "language": "python",
   "name": "privacy_image_3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
