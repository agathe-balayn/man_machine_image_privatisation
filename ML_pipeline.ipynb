{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLab code:\n",
    "# taken from https://gluon-cv.mxnet.io/build/examples_segmentation/demo_deeplab.html\n",
    "# dataset description https://groups.csail.mit.edu/vision/datasets/ADE20K/, https://github.com/dmlc/gluon-cv/blob/master/gluoncv/data/ade20k/segmentation.py\n",
    "# deeplab code https://github.com/dmlc/gluon-cv/blob/master/gluoncv/model_zoo/deeplabv3.py\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import image\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "import gluoncv\n",
    "from gluoncv.data.transforms.presets.segmentation import test_transform\n",
    "\n",
    "# using cpu\n",
    "ctx = mx.cpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR code\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "\n",
    "# If you don't have tesseract executable in your PATH, include the following:\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' # Path('C:/Program Files\\ Tesseract-OCR\\ tesseract').as_posix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Scene recognition imports\n",
    "from Keras_VGG16_places365.vgg16_places_365 import VGG16_Places365\n",
    "from cv2 import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing functions for tesseract (OCR)\n",
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\n",
    "def prepare_dataset(path_image_folder, model_type):\n",
    "    list_image = []\n",
    "    # Go through the directory\n",
    "    list_image_names = []\n",
    "    pathlist = Path(path_image_folder).glob('**/*.*')\n",
    "    for path in pathlist:\n",
    "        # because path is object not string\n",
    "        path_in_str = str(path)\n",
    "        list_image_names.append(path.stem)\n",
    "        # print(path_in_str)\n",
    "        \n",
    "        # check for which model the data will be used and pre-process accordingly.\n",
    "        if model_type == 'deeplab':\n",
    "            img = image.imread(path_in_str)\n",
    "            img = test_transform(img, ctx)\n",
    "        \n",
    "        elif model_type == 'OCR':\n",
    "            img = cv2.imread(path_in_str)\n",
    "            img = get_grayscale(img)\n",
    "            img = thresholding(img)\n",
    "        \n",
    "        elif model_type == 'vgg_places365':\n",
    "            img = Image.open(path_in_str)\n",
    "            img = np.array(img, dtype=np.uint8)\n",
    "            img = resize(img, (224, 224))\n",
    "            img = np.expand_dims(img, 0)\n",
    "\n",
    "        list_image.append(img)\n",
    "\n",
    "    return list_image, list_image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_deeplab, list_image_names_deeplab = prepare_dataset('../small_test2017/', 'deeplab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_OCR, list_image_names_OCR = prepare_dataset('../small_test2017/', 'OCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_scene, list_image_names_scene = prepare_dataset('../small_test2017/', 'vgg_places365')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check that the images are ordred similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_type):\n",
    "    if model_type == 'deeplab':\n",
    "        model = gluoncv.model_zoo.get_model('deeplab_resnet101_ade', pretrained=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADE dataset classes # numbered from 0!\n",
    "CLASSES = (\"wall\", \"building, edifice\", \"sky\", \"floor, flooring\", \"tree\",\n",
    "               \"ceiling\", \"road, route\", \"bed\", \"windowpane, window\", \"grass\",\n",
    "               \"cabinet\", \"sidewalk, pavement\",\n",
    "               \"person, individual, someone, somebody, mortal, soul\",\n",
    "               \"earth, ground\", \"door, double door\", \"table\", \"mountain, mount\",\n",
    "               \"plant, flora, plant life\", \"curtain, drape, drapery, mantle, pall\",\n",
    "               \"chair\", \"car, auto, automobile, machine, motorcar\",\n",
    "               \"water\", \"painting, picture\", \"sofa, couch, lounge\", \"shelf\",\n",
    "               \"house\", \"sea\", \"mirror\", \"rug, carpet, carpeting\", \"field\", \"armchair\",\n",
    "               \"seat\", \"fence, fencing\", \"desk\", \"rock, stone\", \"wardrobe, closet, press\",\n",
    "               \"lamp\", \"bathtub, bathing tub, bath, tub\", \"railing, rail\", \"cushion\",\n",
    "               \"base, pedestal, stand\", \"box\", \"column, pillar\", \"signboard, sign\",\n",
    "               \"chest of drawers, chest, bureau, dresser\", \"counter\", \"sand\", \"sink\",\n",
    "               \"skyscraper\", \"fireplace, hearth, open fireplace\", \"refrigerator, icebox\",\n",
    "               \"grandstand, covered stand\", \"path\", \"stairs, steps\", \"runway\",\n",
    "               \"case, display case, showcase, vitrine\",\n",
    "               \"pool table, billiard table, snooker table\", \"pillow\",\n",
    "               \"screen door, screen\", \"stairway, staircase\", \"river\", \"bridge, span\",\n",
    "               \"bookcase\", \"blind, screen\", \"coffee table, cocktail table\",\n",
    "               \"toilet, can, commode, crapper, pot, potty, stool, throne\",\n",
    "               \"flower\", \"book\", \"hill\", \"bench\", \"countertop\",\n",
    "               \"stove, kitchen stove, range, kitchen range, cooking stove\",\n",
    "               \"palm, palm tree\", \"kitchen island\",\n",
    "               \"computer, computing machine, computing device, data processor, \"\n",
    "               \"electronic computer, information processing system\",\n",
    "               \"swivel chair\", \"boat\", \"bar\", \"arcade machine\",\n",
    "               \"hovel, hut, hutch, shack, shanty\",\n",
    "               \"bus, autobus, coach, charabanc, double-decker, jitney, motorbus, \"\n",
    "               \"motorcoach, omnibus, passenger vehicle\",\n",
    "               \"towel\", \"light, light source\", \"truck, motortruck\", \"tower\",\n",
    "               \"chandelier, pendant, pendent\", \"awning, sunshade, sunblind\",\n",
    "               \"streetlight, street lamp\", \"booth, cubicle, stall, kiosk\",\n",
    "               \"television receiver, television, television set, tv, tv set, idiot \"\n",
    "               \"box, boob tube, telly, goggle box\",\n",
    "               \"airplane, aeroplane, plane\", \"dirt track\",\n",
    "               \"apparel, wearing apparel, dress, clothes\",\n",
    "               \"pole\", \"land, ground, soil\",\n",
    "               \"bannister, banister, balustrade, balusters, handrail\",\n",
    "               \"escalator, moving staircase, moving stairway\",\n",
    "               \"ottoman, pouf, pouffe, puff, hassock\",\n",
    "               \"bottle\", \"buffet, counter, sideboard\",\n",
    "               \"poster, posting, placard, notice, bill, card\",\n",
    "               \"stage\", \"van\", \"ship\", \"fountain\",\n",
    "               \"conveyer belt, conveyor belt, conveyer, conveyor, transporter\",\n",
    "               \"canopy\", \"washer, automatic washer, washing machine\",\n",
    "               \"plaything, toy\", \"swimming pool, swimming bath, natatorium\",\n",
    "               \"stool\", \"barrel, cask\", \"basket, handbasket\", \"waterfall, falls\",\n",
    "               \"tent, collapsible shelter\", \"bag\", \"minibike, motorbike\", \"cradle\",\n",
    "               \"oven\", \"ball\", \"food, solid food\", \"step, stair\", \"tank, storage tank\",\n",
    "               \"trade name, brand name, brand, marque\", \"microwave, microwave oven\",\n",
    "               \"pot, flowerpot\", \"animal, animate being, beast, brute, creature, fauna\",\n",
    "               \"bicycle, bike, wheel, cycle\", \"lake\",\n",
    "               \"dishwasher, dish washer, dishwashing machine\",\n",
    "               \"screen, silver screen, projection screen\",\n",
    "               \"blanket, cover\", \"sculpture\", \"hood, exhaust hood\", \"sconce\", \"vase\",\n",
    "               \"traffic light, traffic signal, stoplight\", \"tray\",\n",
    "               \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, \"\n",
    "               \"dustbin, trash barrel, trash bin\",\n",
    "               \"fan\", \"pier, wharf, wharfage, dock\", \"crt screen\",\n",
    "               \"plate\", \"monitor, monitoring device\", \"bulletin board, notice board\",\n",
    "               \"shower\", \"radiator\", \"glass, drinking glass\", \"clock\", \"flag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(input_data, model_type, loaded_model=''):\n",
    "    \n",
    "    if model_type == 'vgg_places365':\n",
    "        file_name = Path('Keras_VGG16_places365/categories_places365.txt')\n",
    "        if not os.access(file_name, os.W_OK):\n",
    "            synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "            os.system('wget ' + synset_url)\n",
    "        classes = list()\n",
    "        with open(file_name) as class_file:\n",
    "            for line in class_file:\n",
    "                classes.append(line.strip().split(' ')[0][3:])\n",
    "        classes = tuple(classes)\n",
    "    \n",
    "    output = []\n",
    "    for img in input_data:\n",
    "        if model_type == 'deeplab':\n",
    "            pred = loaded_model.predict(img)\n",
    "            # Check what the outputs of predict are: is it probability? does it depend on the class or is it class-agnostic?\n",
    "            idx_labels = mx.nd.squeeze(mx.nd.argmax(pred, 1)).asnumpy()\n",
    "            # Decide later whether we make it into actual labels.\n",
    "            output.append((pred, idx_labels)) # this gives both the prediction \"confidence\" and the final label (in idx).\n",
    "        elif model_type == 'OCR': \n",
    "            pred = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "            prediction_list = []\n",
    "            # Get the boundix boxes around the words\n",
    "            n_boxes = len(pred['text'])\n",
    "            for i in range(n_boxes):\n",
    "                # if int(pred['conf'][i]) > 60: to filter per confidence ! see later!\n",
    "                (x, y, w, h) = (pred['left'][i], pred['top'][i], pred['width'][i], pred['height'][i])\n",
    "                prediction_list.append((pred['text'][i], (x, y, w, h)))\n",
    "            output.append(prediction_list)\n",
    "        elif model_type == 'vgg_places365':\n",
    "            model = VGG16_Places365(weights='places')\n",
    "            #predictions_to_return = 5\n",
    "            preds = model.predict(img)[0]\n",
    "            top_preds = np.argsort(preds)[::-1]#[0:predictions_to_return]\n",
    "            top_preds_score = [preds[i] for i in top_preds]\n",
    "            prediction_list = []\n",
    "            for i in range(0, len(top_preds)):\n",
    "                prediction_list.append((classes[top_preds[i]], top_preds_score[i]))\n",
    "            output.append(prediction_list)\n",
    "\n",
    "    return output\n",
    "        \n",
    "    # Add post processing to reshape the image / bounding boxes /  to original size\n",
    "    # It seems there's no need for that becaause only the scene recognition model needs resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deeplab = load_model('deeplab')\n",
    "output_pred_deeplab = get_predictions(image_list_deeplab, 'deeplab', model_deeplab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_ocr = get_predictions(image_list_OCR, 'OCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred_scene = get_predictions(image_list_scene, 'vgg_places365')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "def evaluate_privacy(ground_truth, predictions, overlap_treshold):\n",
    "    ### Read ground truth \n",
    "    # Go through each private element in GT\n",
    "    # Go through each private element in predictions\n",
    "    # Compute overlap\n",
    "    # Get the max and compare with threshold\n",
    "    for private_elem in ground_truth\n",
    "    return list_perf_per_private_element\n",
    "\n",
    "def evaluate_instance(ground_truth, predictions, segmentation_size):\n",
    "    \n",
    "    return list_perf_per_private_element\n",
    "\n",
    "def evaluate(ground_truth, predictions, evaluation_type, parameter_interval):\n",
    "    if evaluation_type == 'privacy_type':\n",
    "        for param_eval in parameter_interval:\n",
    "            type_private_elements = []\n",
    "            for idx_im in range(len(predictions)):\n",
    "                # Get the ground truth \n",
    "                # Name of the image\n",
    "                im_name = list_image_names_deeplab[idx_im]\n",
    "                result = evaluate_privacy(ground_truth[im_name], predictions[idx_im])\n",
    "                result.append(type_private_elements)\n",
    "            print(\"TODO\")\n",
    "            # And aggreagte\n",
    "    elif evaluation_type == 'instance_type':\n",
    "        for param_eval in parameter_interval:\n",
    "            print(\"TODO\")\n",
    "        # And aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read ground truth file and get the actual annotations\n",
    "with open(Path('../test2017.json'), 'r') as f:\n",
    "    ground_truth = json.load(f)\n",
    "ground_truth = ground_truth['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privacy_image_3_7",
   "language": "python",
   "name": "privacy_image_3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
